To learn representations of input speech samples, I use a neural network, 
or rather a family of similar neural networks all sharing the same 
sequence-to-sequence architecture. This architecture consists of an 
encoder, a decoder, and an attention mechanism, each of which will be discussed 
in greater detail below.

